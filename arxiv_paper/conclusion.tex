\section{Conclusion}

% Summary of contributions.
Approximate abstraction in \acp{MDP} offers considerable advantages over exact abstraction. First, approximate abstraction relies on criteria that we imagine a planning or learning algorithm to be able to learn without solving the full \ac{MDP}. Second, approximate abstractions can achieve greater degrees of compression due to their relaxed criteria of equality. Third, methods that employ approximate aggregation techniques are able to tune the aggressiveness of abstraction all the while incurring bounded error. In this work, we proved bounds for the value lost when behaving according to the optimal policy of the abstract \ac{MDP}, and empirically demonstrate that approximate abstractions can reduce state space size with minor loss in the quality of the behavior. We provide a code base that provides implementations to abstract, visualize, and evaluate an arbitrary MDP to promote further investigation into approximate abstraction.


%We empirically demonstrate the relationship between $\varepsilon$ and the degree of compression, as well as the value of the abstract policy on four dramatically different \acs{MDP}. 



% Future work.
There are many directions for future work.
% Learning abs functions online.
First, we are interested in extending the approach of \citet{ortner2013adaptive} by learning the approximate abstraction functions introduced in this paper online in the planning or \ac{RL} setting, particularly when the agent must solve a collection of related MDPs.
% Necessary conditions.
While our work presents several sufficient conditions for achieving bounded error of learned behavior with approximate abstractions, we hope to investigate what conditions are strictly necessary for an approximate abstraction to achieve bounded error.
% Options/termporal abstraction
%We investigated the use of options in the Taxi domain, and found a negligible difference in the degree and quality of compression compared to compression without options. 
Further, we are interested in characterizing the relationship between temporal abstractions, such as options ~\cite{sutton1999between}, and approximate abstractions.
% Compressibility
Lastly, we are interested in understanding the relationship between various approximate abstractions and the information theoretical limitations on the degree of abstraction achievable in \acp{MDP}.

% Exploration is interesting.
%Learning abstraction functions online also has interesting implications for the exploration problem. If certain information informs the agent's ability to abstract more quickly, then exploration directed at learning the abstraction function introduces a new notion of exploration, as an abstraction function will enable the agent to identify near-optimal behavior more quickly, 
