@inproceedings{li2006towards,
  title={Towards a Unified Theory of State Abstraction for MDPs.},
  author={Li, Lihong and Walsh, Thomas J and Littman, Michael L},
  booktitle={ISAIM},
  year={2006}
}

@article{Bellemare2015,
arxivId = {1512.04860},
author = {Bellemare, Marc G. and Ostrovski, Georg and Guez, Arthur and Thomas, Philip S. and Munos, R{\'{e}}mi},
file = {:Users/dabel/Research/Mendeley/Bellemare et al/Bellemare et al. - 2015 - Increasing the Action Gap New Operators for Reinforcement Learning.pdf:pdf},
title = {{Increasing the Action Gap: New Operators for Reinforcement Learning}},
url = {http://arxiv.org/abs/1512.04860},
year = {2015}
}

@article{Jiang2015,
author = {Jiang, Nan},
title = {{Abstraction Selection in Model-Based Reinforcement Learning}},
volume = {37},
year = {2015}
}


@inproceedings{andre2002state,
  title={State abstraction for programmable reinforcement learning agents},
  author={Andre, David and Russell, Stuart J},
  booktitle={AAAI/IAAI},
  pages={119--125},
  year={2002}
}

@article{ravindran2003smdp,
  title={SMDP homomorphisms: An algebraic approach to abstraction in semi markov decision processes},
  author={Ravindran, Balaraman},
  year={2003}
}

@inproceedings{jiang2015abstraction,
  title={Abstraction Selection in Model-based Reinforcement Learning},
  author={Jiang, Nan and Kulesza, Alex and Singh, Satinder},
  booktitle={Proceedings of The 32nd International Conference on Machine Learning},
  pages={179--188},
  year={2015}
}

@inproceedings{jong2005state,
  title={State Abstraction Discovery from Irrelevant State Variables.},
  author={Jong, Nicholas K and Stone, Peter},
  booktitle={IJCAI},
  pages={752--757},
  year={2005},
}

@inproceedings{ortner2014selecting,
  title={Selecting near-optimal approximate state representations in reinforcement learning},
  author={Ortner, Ronald and Maillard, Odalric-Ambrym and Ryabko, Daniil},
  booktitle={Algorithmic Learning Theory},
  pages={140--154},
  year={2014},
  organization={Springer}
}

@inproceedings{maillard2011selecting,
  title={Selecting the state-representation in reinforcement learning},
  author={Maillard, Odalric-Ambrym and Ryabko, Daniil and Munos, R{\'e}mi},
  booktitle={Advances in Neural Information Processing Systems},
  pages={2627--2635},
  year={2011}
}

@article{Bean2011,
author = {Bean, James C and Birge, John R and Smith, Robert L},
journal = {Operation research},
number = {2},
pages = {215--220},
title = {{Dynamic Programming Aggregation}},
volume = {35},
year = {2011}
}

@article{Boutilier2000,
author = {Boutilier, C and Dearden, Richard and Goldszmidt, M},
issn = {0004-3702},
journal = {Artificial Intelligence},
number = {1-2},
pages = {49--107},
title = {{Stochastic dynamic programming with factored representations}},
volume = {121},
year = {2000}
}

@inproceedings{dean1997model,
  title={Model reduction techniques for computing approximately optimal solutions for Markov decision processes},
  author={Dean, Thomas and Givan, Robert and Leach, Sonia},
  booktitle={Proceedings of the Thirteenth conference on Uncertainty in artificial intelligence},
  pages={124--131},
  year={1997},
  organization={Morgan Kaufmann Publishers Inc.}
}